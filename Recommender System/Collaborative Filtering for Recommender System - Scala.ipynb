{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://10.226.156.86:4040\n",
       "SparkContext available as 'sc' (version = 2.1.1, master = local[*], app id = local-1503347694087)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@17bbbdf1\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "val spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "data: org.apache.spark.sql.DataFrame = [userId: int, movieId: int ... 1 more field]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data = (spark.read.option(\"header\",\"true\")\n",
    "            .option(\"inferSchema\",\"true\")\n",
    "            .csv(\"movie_ratings.csv\"))\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|summary|            userId|           movieId|            rating|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|  count|            100004|            100004|            100004|\n",
      "|   mean| 347.0113095476181|12548.664363425463| 3.543608255669773|\n",
      "| stddev|195.16383797819535|26369.198968815268|1.0580641091070326|\n",
      "|    min|                 1|                 1|               0.5|\n",
      "|    max|               671|            163949|               5.0|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userId: int, movieId: int ... 1 more field]\r\n",
       "test: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userId: int, movieId: int ... 1 more field]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Splitting the data into train set and test set\n",
    "val Array(training, test) = data.randomSplit(Array(0.8, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** When making predictions using Alternative least square(ALS) method, it is common to encounter users and/or items in the test dataset that were not present during training the model. This amy cause 'NaN' predicted values in result for evaluation metrics. So, Spark has a feature called 'coldStartStrategy' to reslove this issue. ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|   575|    148|   4.0|       NaN|\n",
      "|   452|    463|   2.0|  2.525254|\n",
      "|   588|    471|   3.0| 3.9335432|\n",
      "|   460|    471|   5.0| 3.2634168|\n",
      "|   306|    471|   3.0| 3.5716166|\n",
      "|   491|    471|   3.0| 3.3785546|\n",
      "|   502|    471|   4.0|  4.505924|\n",
      "|   241|    471|   4.0| 3.2869341|\n",
      "|   487|    471|   4.0| 3.5859377|\n",
      "|   399|    471|   5.0|  3.345561|\n",
      "+------+-------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.recommendation.ALS\r\n",
       "als: org.apache.spark.ml.recommendation.ALS = als_746342d2fd7f\r\n",
       "model: org.apache.spark.ml.recommendation.ALSModel = als_746342d2fd7f\r\n",
       "pred: org.apache.spark.sql.DataFrame = [userId: int, movieId: int ... 2 more fields]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Developing recommnedation system model\n",
    "// Alternative least square(ALS) method\n",
    "import org.apache.spark.ml.recommendation.ALS\n",
    "val als = (new ALS()  \n",
    "           .setMaxIter(5)  // number of iterations to run\n",
    "           .setRegParam(0.01) // regularization parameter\n",
    "           .setUserCol(\"userId\")  \n",
    "           .setItemCol(\"movieId\")  \n",
    "           .setRatingCol(\"rating\")\n",
    "//            .setColdStartStrategy(\"drop\") // we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "          )\n",
    "\n",
    "// Fitting the model with training data\n",
    "val model = als.fit(training)\n",
    "\n",
    "// Checking the prediction with test data\n",
    "val pred = model.transform(test)\n",
    "pred.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.109687797412326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.evaluation.RegressionEvaluator\r\n",
       "evaluator: org.apache.spark.ml.evaluation.RegressionEvaluator = regEval_8f81fb87febe\r\n",
       "rmse: Double = 1.109687797412326\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Evaluating the model\n",
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "val evaluator = (new RegressionEvaluator()\n",
    "                 .setMetricName(\"rmse\")\n",
    "                 .setLabelCol(\"rating\")\n",
    "                 .setPredictionCol(\"prediction\")\n",
    "                )\n",
    "val rmse = evaluator.evaluate(pred.na.drop())\n",
    "println($\"RMSE: $rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|movieId|userId|\n",
      "+-------+------+\n",
      "|    778|    11|\n",
      "|   1027|    11|\n",
      "|   6598|    11|\n",
      "+-------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "single_user: org.apache.spark.sql.DataFrame = [movieId: int, userId: int]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// How can we use this model to recommend a movie to a new single user\n",
    "val single_user = test.filter($\"userId\" === 11).select(\"movieId\", \"userId\")\n",
    "single_user.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+\n",
      "|movieId|userId|prediction|\n",
      "+-------+------+----------+\n",
      "|   6598|    11| 0.8916418|\n",
      "|   1027|    11| 2.7821307|\n",
      "|    778|    11|  4.510311|\n",
      "+-------+------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\r\n",
       "recommendations: org.apache.spark.sql.DataFrame = [movieId: int, userId: int ... 1 more field]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Let's predict how this user going to like the above mentioned movies\n",
    "import org.apache.spark.sql.functions._\n",
    "val recommendations = model.transform(single_user)\n",
    "recommendations.orderBy($\"movieId\".desc).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|    11|   6598|   5.0|\n",
      "|    11|   1027|   4.5|\n",
      "|    11|    778|   4.5|\n",
      "+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Let's check our prediction against the actual data to see how well our model perform\n",
    "test.filter($\"userId\" === 11).orderBy($\"movieId\".desc).show(10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
