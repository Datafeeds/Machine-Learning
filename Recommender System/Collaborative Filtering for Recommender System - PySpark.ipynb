{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('Path_to_Spark_Installation_Folder')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv('movie_ratings.csv', header = True, inferSchema = True)\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|summary|            userId|           movieId|            rating|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|  count|            100004|            100004|            100004|\n",
      "|   mean| 347.0113095476181|12548.664363425463| 3.543608255669773|\n",
      "| stddev|195.16383797819535|26369.198968815268|1.0580641091070326|\n",
      "|    min|                 1|                 1|               0.5|\n",
      "|    max|               671|            163949|               5.0|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the data into train set and test set\n",
    "train, test = data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** When making predictions using Alternative least square(ALS) method, it is common to encounter users and/or items in the test dataset that were not present during training the model. This amy cause 'NaN' predicted values in result for evaluation metrics. So, Spark has a feature called 'coldStartStrategy' to reslove this issue. ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|   575|    148|   4.0|       NaN|\n",
      "|   232|    463|   4.0| 2.5138907|\n",
      "|   242|    463|   4.0|  3.077727|\n",
      "|   311|    463|   3.0| 1.7966607|\n",
      "|   460|    471|   5.0|  3.472546|\n",
      "|   491|    471|   3.0| 4.2521105|\n",
      "|   607|    471|   4.0| 3.1809988|\n",
      "|   358|    471|   5.0| 3.7823098|\n",
      "|    23|    471|   3.5| 3.6827884|\n",
      "|   105|    471|   4.0| 3.6581256|\n",
      "+------+-------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Developing recommnedation system model\n",
    "# Alternative least square(ALS) method\n",
    "from pyspark.ml.recommendation import ALS\n",
    "als = ALS(maxIter = 5, #  number of iterations to run\n",
    "          regParam = 0.01, # regularization parameter\n",
    "          userCol = 'userId',\n",
    "          itemCol = 'movieId',\n",
    "          ratingCol = 'rating',\n",
    "#           coldStartStrategy = 'drop' # we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "         )\n",
    "\n",
    "# Fitting the model with training data\n",
    "model = als.fit(train)\n",
    "\n",
    "# Checking the prediction with test data\n",
    "pred = model.transform(test)\n",
    "pred.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.12\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName = 'rmse', labelCol = 'rating', predictionCol = 'prediction')\n",
    "rmse = evaluator.evaluate(pred.na.drop())\n",
    "print('RMSE: %.2f'%rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|movieId|userId|\n",
      "+-------+------+\n",
      "|    296|    11|\n",
      "|    785|    11|\n",
      "|   1201|    11|\n",
      "|   1408|    11|\n",
      "|   3424|    11|\n",
      "|  48516|    11|\n",
      "|  58295|    11|\n",
      "|  79132|    11|\n",
      "| 106487|    11|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How can we use this model to recommend a movie to a new single user\n",
    "single_user = test.filter(test['userId'] == 11).select(['movieId', 'userId'])\n",
    "single_user.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+\n",
      "|movieId|userId|prediction|\n",
      "+-------+------+----------+\n",
      "| 106487|    11| 3.6910338|\n",
      "|  79132|    11| 4.2264347|\n",
      "|  58295|    11| 3.4234211|\n",
      "|  48516|    11| 4.2861857|\n",
      "|   3424|    11|  5.153322|\n",
      "|   1408|    11| 2.9022808|\n",
      "|   1201|    11|  5.137532|\n",
      "|    785|    11| 4.0600085|\n",
      "|    296|    11| 4.9990373|\n",
      "+-------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's predict how this user going to like the above mentioned movies\n",
    "recommendations = model.transform(single_user)\n",
    "recommendations.orderBy('movieId', ascending = False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|    11| 106487|   5.0|\n",
      "|    11|  79132|   4.0|\n",
      "|    11|  58295|   4.5|\n",
      "|    11|  48516|   5.0|\n",
      "|    11|   3424|   3.0|\n",
      "|    11|   1408|   5.0|\n",
      "|    11|   1201|   5.0|\n",
      "|    11|    785|   3.5|\n",
      "|    11|    296|   5.0|\n",
      "+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check our prediction against the actual data to see how well our model perform\n",
    "test.filter(test['userId'] == 11).orderBy('movieId', ascending = False).show(10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
