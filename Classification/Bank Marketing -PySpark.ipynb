{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('directory_to_spark_installation')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "data = spark.read.csv('bank.csv', \n",
    "                      header = True, \n",
    "                      inferSchema = True,\n",
    "                      sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'balance',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'day',\n",
       " 'month',\n",
       " 'duration',\n",
       " 'campaign',\n",
       " 'pdays',\n",
       " 'previous',\n",
       " 'poutcome',\n",
       " 'y']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "|age|         job| marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n",
      "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "| 58|  management| married| tertiary|     no|   2143|    yes|  no|unknown|  5|  may|     261|       1|   -1|       0| unknown| no|\n",
      "| 44|  technician|  single|secondary|     no|     29|    yes|  no|unknown|  5|  may|     151|       1|   -1|       0| unknown| no|\n",
      "| 33|entrepreneur| married|secondary|     no|      2|    yes| yes|unknown|  5|  may|      76|       1|   -1|       0| unknown| no|\n",
      "| 47| blue-collar| married|  unknown|     no|   1506|    yes|  no|unknown|  5|  may|      92|       1|   -1|       0| unknown| no|\n",
      "| 33|     unknown|  single|  unknown|     no|      1|     no|  no|unknown|  5|  may|     198|       1|   -1|       0| unknown| no|\n",
      "| 35|  management| married| tertiary|     no|    231|    yes|  no|unknown|  5|  may|     139|       1|   -1|       0| unknown| no|\n",
      "| 28|  management|  single| tertiary|     no|    447|    yes| yes|unknown|  5|  may|     217|       1|   -1|       0| unknown| no|\n",
      "| 42|entrepreneur|divorced| tertiary|    yes|      2|    yes|  no|unknown|  5|  may|     380|       1|   -1|       0| unknown| no|\n",
      "| 58|     retired| married|  primary|     no|    121|    yes|  no|unknown|  5|  may|      50|       1|   -1|       0| unknown| no|\n",
      "| 43|  technician|  single|secondary|     no|    593|    yes|  no|unknown|  5|  may|      55|       1|   -1|       0| unknown| no|\n",
      "| 41|       admin|divorced|secondary|     no|    270|    yes|  no|unknown|  5|  may|     222|       1|   -1|       0| unknown| no|\n",
      "| 29|       admin|  single|secondary|     no|    390|    yes|  no|unknown|  5|  may|     137|       1|   -1|       0| unknown| no|\n",
      "| 53|  technician| married|secondary|     no|      6|    yes|  no|unknown|  5|  may|     517|       1|   -1|       0| unknown| no|\n",
      "| 58|  technician| married|  unknown|     no|     71|    yes|  no|unknown|  5|  may|      71|       1|   -1|       0| unknown| no|\n",
      "| 57|    services| married|secondary|     no|    162|    yes|  no|unknown|  5|  may|     174|       1|   -1|       0| unknown| no|\n",
      "| 51|     retired| married|  primary|     no|    229|    yes|  no|unknown|  5|  may|     353|       1|   -1|       0| unknown| no|\n",
      "| 45|       admin|  single|  unknown|     no|     13|    yes|  no|unknown|  5|  may|      98|       1|   -1|       0| unknown| no|\n",
      "| 57| blue-collar| married|  primary|     no|     52|    yes|  no|unknown|  5|  may|      38|       1|   -1|       0| unknown| no|\n",
      "| 60|     retired| married|  primary|     no|     60|    yes|  no|unknown|  5|  may|     219|       1|   -1|       0| unknown| no|\n",
      "| 33|    services| married|secondary|     no|      0|    yes|  no|unknown|  5|  may|      54|       1|   -1|       0| unknown| no|\n",
      "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### All feature \n",
    "age, job, marital, education, default, balance, housing, loan, contact, day, month, duration, campaign, pdays, previous, poutcome, y\n",
    "\n",
    "##### Features being Considered\n",
    "age, job, marital,  default, balance, housing, loan, duration, campaign, pdays, previous, poutcome, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|poutcome|count|\n",
      "+--------+-----+\n",
      "| success| 1511|\n",
      "| unknown|36959|\n",
      "|   other| 1840|\n",
      "| failure| 4901|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy('poutcome').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'poutcome' seems to be important feature. However, the previous outcome was unknown for majority of the customers. So, It is better to drop this feature.\n",
    "\n",
    "##### Final Features being Considered\n",
    "age, job, marital,  default, balance, housing, loan, duration, campaign, pdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------+--------+-------+------------------+-------+-----+-----------------+-----------------+------------------+-----+\n",
      "|summary|               age|    job| marital|default|           balance|housing| loan|         duration|         campaign|             pdays|    y|\n",
      "+-------+------------------+-------+--------+-------+------------------+-------+-----+-----------------+-----------------+------------------+-----+\n",
      "|  count|             45211|  45211|   45211|  45211|             45211|  45211|45211|            45211|            45211|             45211|45211|\n",
      "|   mean| 40.93621021432837|   null|    null|   null|1362.2720576850766|   null| null|258.1630797814691|2.763840658246887| 40.19782796222158| null|\n",
      "| stddev|10.618762040975405|   null|    null|   null|3044.7658291685257|   null| null|257.5278122651706|3.098020883279192|100.12874599059828| null|\n",
      "|    min|                18|  admin|divorced|     no|             -8019|     no|   no|                0|                1|                -1|   no|\n",
      "|    max|                95|unknown|  single|    yes|            102127|    yes|  yes|             4918|               63|               871|  yes|\n",
      "+-------+------------------+-------+--------+-------+------------------+-------+-----+-----------------+-----------------+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data = data.select('age', 'job', 'marital', 'default', 'balance', 'housing', 'loan', 'duration', 'campaign', 'pdays', 'y')\n",
    "final_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no null values in the columns being considered. Good to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Converting string values to numerical column\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "\n",
    "JobIndexer = StringIndexer(inputCol = 'job', outputCol = 'JobIndex')\n",
    "MaritalIndexer = StringIndexer(inputCol = 'marital', outputCol = 'MaritalIndex')\n",
    "DefaultIndexer = StringIndexer(inputCol = 'default', outputCol = 'DefaultIndex')\n",
    "HousingIndexer = StringIndexer(inputCol = 'housing', outputCol = 'HousingIndex')\n",
    "LoanIndexer = StringIndexer(inputCol = 'loan', outputCol = 'LoanIndex')\n",
    "LabelIndexer = StringIndexer(inputCol = 'y', outputCol = 'label')\n",
    "\n",
    "# Using OneHotEncoder to avoid hierarchy in numerical value obtaied in above step\n",
    "JobEncoder = OneHotEncoder(inputCol = 'JobIndex', outputCol = 'JobVec')\n",
    "MaritalEncoder = OneHotEncoder(inputCol = 'MaritalIndex', outputCol = 'MaritalkVec')\n",
    "\n",
    "# All the other columns have binary values(either Yes or No). So no need to hotencode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assemble everything together to be (\"label\",\"features\") format\n",
    "assembler = VectorAssembler(inputCols = ['age', 'JobVec', 'MaritalkVec', 'DefaultIndex', 'balance', \n",
    "                                    'HousingIndex', 'LoanIndex', 'duration', 'campaign', 'pdays'],\n",
    "                           outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scaling the features\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "scaler = StandardScaler(inputCol = 'features', outputCol = 'scaledFeatures', withStd = True, withMean = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Spliting the data into Training set and Test set\n",
    "train_data, test_data =  final_data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defining Classifier Model\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "\n",
    "lr = LogisticRegression()\n",
    "rcf = RandomForestClassifier(maxDepth = 10, numTrees = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set Up the Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# *************************** For Logistic Regressor ***************************\n",
    "# pipeline = Pipeline(stages=[JobIndexer, MaritalIndexer, DefaultIndexer, HousingIndexer, \n",
    "#                             LoanIndexer, LabelIndexer, JobEncoder, MaritalEncoder, assembler, scaler, lr])\n",
    "\n",
    "# *************************** For Random Forest Classifier ***************************\n",
    "pipeline = Pipeline(stages=[JobIndexer, MaritalIndexer, DefaultIndexer, HousingIndexer, \n",
    "                            LoanIndexer, LabelIndexer, JobEncoder, MaritalEncoder, assembler, scaler, rcf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "# Geting results on Test set\n",
    "results = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       0.0|\n",
      "|  0.0|       1.0|\n",
      "|  0.0|       1.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       1.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.select('label', 'prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "# Model selection is still in RDD phase. So We will use rdd here instead of spark dataframe. \n",
    "# This will be update in future versions of Spark\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "predictionAndLabels = results.select('prediction', 'label').rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 7657.   164.]\n",
      " [  845.   251.]]\n",
      "Accuracy: 0.89\n",
      "Precision: 0.86\n"
     ]
    }
   ],
   "source": [
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "# Confusion Matrix\n",
    "print('Confusion Matrix')\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print('Accuracy: %.2f'%metrics.accuracy)\n",
    "print('Precision: %.2f'%metrics.weightedPrecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
